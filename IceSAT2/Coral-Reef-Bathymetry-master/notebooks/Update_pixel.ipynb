{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import plot\n",
    "import math\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "#machine learning packages \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#plotting packages\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing other python files \n",
    "import src.Tide_API as tide\n",
    "import src.Depth_profile as depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ksunil/Desktop/Karan/Codebase'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to get the metadata of the images\n",
    "def get_metadata(fp,meta):\n",
    "    #opening file containing metadata\n",
    "    file = open(fp,\"r\")\n",
    "    contents = file.read()\n",
    "    soup = BeautifulSoup(contents,'xml')\n",
    "    #getting the time of the image and creating a datetime object \n",
    "    dt = (soup.find('SENSING_TIME').text.split('.')[0].replace('T',''))\n",
    "    meta['dt'] = datetime.strptime(dt, '%Y-%m-%d%H:%M:%S')\n",
    "    \n",
    "    #getting the latitude and longitude to calculate the tide at the given point \n",
    "    lat = (meta['coords'][1] + meta['coords'][1])/2\n",
    "    lon = (meta['coords'][2] + meta['coords'][0])/2\n",
    "    #getting the tide on the day of the image \n",
    "    meta['tide_level'] = tide.get_tide(lat,lon,meta['dt'])\n",
    "    print(meta['tide_level'])\n",
    "    \n",
    "    #getting the crs of the image \n",
    "    geo_info = soup.find('n1:Geometric_Info')\n",
    "    meta['crs'] = geo_info.find('HORIZONTAL_CS_CODE').text.lower()\n",
    "    meta['bbox'] = get_bbox(meta['coords'],meta['crs'])\n",
    "    \n",
    "    #getting the number of rows and columns in the image \n",
    "    rc = geo_info.find('Size' , {'resolution':\"10\"})\n",
    "    meta['rows'] = int(rc.find('NROWS').text)\n",
    "    meta['cols'] = int(rc.find('NCOLS').text)\n",
    "    \n",
    "    #getting the upper left x and y coordinates \n",
    "    geo_pos = geo_info.find('Geoposition' , {'resolution':\"10\"})\n",
    "    meta['ulx'] = int(geo_pos.find('ULX').text)\n",
    "    meta['uly'] = int(geo_pos.find('ULY').text)\n",
    "    \n",
    "    #getting the step of the image in the x and y dircetions \n",
    "    meta['xdim'] = int(geo_pos.find('XDIM').text)\n",
    "    meta['ydim'] = int(geo_pos.find('YDIM').text)\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "    #getting a polygon representing the shape of the reef \n",
    "    meta['polygon'] = read_gjson(meta)\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bbox(coords,crs):\n",
    "    #creates a bounding box for just the reef we are interested in \n",
    "    ul = (coords[0], coords[3])\n",
    "    br = (coords[2], coords[1])\n",
    "    bbox = pd.DataFrame([ul,br], columns = ['Longitude','Latitude'])\n",
    "    bbox['Coordinates'] = list(zip(bbox.Longitude, bbox.Latitude))\n",
    "    bbox['Coordinates'] = bbox.Coordinates.apply(Point)\n",
    "    #converts the coordinates of the bounding box to the crs of the image \n",
    "    bbox = gpd.GeoDataFrame(bbox, geometry = 'Coordinates')\n",
    "    bbox.crs = {'init': 'epsg:4326'}\n",
    "    bbox = bbox.to_crs(crs)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to read in the polygon representing the shape of the reef\n",
    "def read_gjson(meta):\n",
    "    #creating the filepath for the geojson file \n",
    "    fp = os.path.join(meta['data_dir'], meta['reef_name'], str(meta['reef_name']) +'.geojson')\n",
    "    #loading in the geojson file into a geopandas dataframe \n",
    "    df = gpd.read_file(fp)\n",
    "    #setting the current crs of the dataframe \n",
    "    df.crs = {'init': 'epsg:4326'}\n",
    "    #changing the crs to that of the sentinel image \n",
    "    df = df.to_crs(meta['crs'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_df(fp,meta):\n",
    "    #reading in the depths \n",
    "    df = pd.DataFrame.from_csv(fp)\n",
    "    #adjusting the heights based on the tide on the given day\n",
    "    df.Height = df.Height + meta['tide_level']\n",
    "\n",
    "    #converts the lat and lon to the crs of the image \n",
    "    df['Coordinates'] = list(zip(df.Longitude, df.Latitude))\n",
    "    df['Coordinates'] = df.Coordinates.apply(Point)\n",
    "    df = gpd.GeoDataFrame(df, geometry = 'Coordinates')\n",
    "    df.crs = {'init': 'epsg:4326'}\n",
    "    df = df.to_crs(meta['crs'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to load in all the images \n",
    "def get_images(base_fp,meta):\n",
    "    #select the bands that we want \n",
    "    bands = ['B02','B03','B04','B08']\n",
    "    imgs = []\n",
    "    black = {}\n",
    "    #loops through the bands \n",
    "    for b in bands:\n",
    "        img_path = list(Path(base_fp).glob('**/' + 'IMG_DATA' + '/*'+b+'*.jp2'))[0]\n",
    "\n",
    "        #reads in image \n",
    "        band = rasterio.open(img_path, driver = 'JP2OpenJPEG')\n",
    "        #reads in pixel values \n",
    "        img = band.read(1)\n",
    "        #adds delta to each pixel value, so that we never take log(0)\n",
    "        delta = 0.0001\n",
    "        img = np.add(img,delta)\n",
    "        \n",
    "        #get the coordinates of the bounding box \n",
    "        start_x = meta['bbox'].loc[0,'Coordinates'].x\n",
    "        start_y = meta['bbox'].loc[0,'Coordinates'].y\n",
    "\n",
    "        sx = int((start_x - meta['ulx']) // meta['xdim'])\n",
    "        sy = int((start_y - meta['uly']) // meta['ydim'])\n",
    "\n",
    "        end_x = meta['bbox'].loc[1,'Coordinates'].x\n",
    "        end_y = meta['bbox'].loc[1,'Coordinates'].y\n",
    "\n",
    "        ex = int((end_x - meta['ulx']) // meta['xdim']) \n",
    "        ey = int((end_y - meta['uly']) // meta['ydim']) \n",
    "        \n",
    "        #clip the image to the coordinates of the bounding box \n",
    "        img = [row[sx:ex] for row in (img[sy:ey])]\n",
    "        \n",
    "        imgs.append(img)\n",
    "    #return the images\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method that trains a regression model and returns the same \n",
    "def get_regressor(base_fp,meta):\n",
    "    #gets the metadata \n",
    "    fp = os.path.join(base_fp,'MTD_TL.xml')\n",
    "    meta = get_metadata(fp,meta)\n",
    "    \n",
    "    #creating a training dataset using ICESAT 2 depth profile \n",
    "    reef = pd.DataFrame()\n",
    "    icesat_proc_fp = os.path.join(meta['data_dir'], meta['reef_name'], 'Output', 'Data Cleaning','processed-output')\n",
    "    for fn in os.listdir(icesat_proc_fp):\n",
    "        training_fp = os.path.join(icesat_proc_fp, fn)\n",
    "        reef = pd.concat([reef,prep_df(training_fp,meta)])\n",
    "\n",
    "    #drop any nan rows \n",
    "    reef = reef.dropna()\n",
    "    \n",
    "    #loads in the different band images required \n",
    "    imgs = get_images(base_fp,meta)\n",
    "    meta['imgs'] = imgs\n",
    "    #creates the masking threshold for band 8 to mask land and clouds \n",
    "    b8_pix = (meta['imgs'][3])\n",
    "    meta['mask_thresh'] = np.median(b8_pix) + (np.std(b8_pix))\n",
    "    \n",
    "    #method to get just the pixel values of our bounding box \n",
    "    def get_pixel_val(coord):\n",
    "        x_index = int((coord.x - meta['bbox'].Coordinates.x[0]) // meta['xdim']) \n",
    "        y_index = int((coord.y - meta['bbox'].Coordinates.y[0]) // meta['ydim']) \n",
    "        return [data[y_index][x_index] for data in imgs]\n",
    "\n",
    "    #extracts the different band values for our image \n",
    "    def extract_pixel_cols(df):\n",
    "        df['Pixels'] = df.Coordinates.apply(get_pixel_val)\n",
    "        df['b2'] = df.Pixels.apply(lambda x: (x[0]))\n",
    "        df['b3'] = df.Pixels.apply(lambda x: (x[1]))\n",
    "        df['b8'] = df.Pixels.apply(lambda x: (x[3]))\n",
    "        #converts points with pixel values above the mask to nan\n",
    "        df['mask'] = df.b8.apply(lambda x: x if x < meta['mask_thresh'] else np.nan)\n",
    "        return df\n",
    "\n",
    "    reef = extract_pixel_cols(reef)\n",
    "    #drop all rows that are land or clouds \n",
    "    reef = reef.dropna(subset = ['mask'])\n",
    "    \n",
    "    #stroes the x and y coordinates in individual columns \n",
    "    reef['x'] = reef.Coordinates.x\n",
    "    reef['y'] = reef.Coordinates.y\n",
    "#     removing training data that are above -2m\n",
    "#     reef = reef.loc[reef.Height < -2]\n",
    "\n",
    "    \n",
    "    #gets just the required input columns \n",
    "    y = reef.loc[:,['b2','b3']] \n",
    "\n",
    "    meta['min_pix'] = {'B02': min(y.b2), 'B03': min(y.b3)}\n",
    "    bp = meta['min_pix']\n",
    "    y['b2'] = y['b2'].apply(lambda x: max(1,x - bp['B02']))\n",
    "    y['b3'] = y['b3'].apply(lambda x: max(1,x - bp['B03']))\n",
    "    y['diff'] = y.apply(lambda x: (math.log(x['b2']) - math.log(x['b3'])), axis = 1)\n",
    "    y['Height'] = reef.loc[:,['Height']]\n",
    "    y['x'] = reef.Coordinates.x\n",
    "    y['y'] = reef.Coordinates.y\n",
    "    \n",
    "    reef = remove_log_outliers(y)\n",
    "    #gets the column that we are trying to predict \n",
    "    y = reef.loc[:,['diff']]\n",
    "    x = reef.loc[:,['Height']]\n",
    "    #performs a train test split, putting 33% of the data in the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state =3)\n",
    "\n",
    "    #fit a linear regression ridge model to our data\n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.HuberRegressor()\n",
    "#     reg = LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    \n",
    "    #predicts values for our test set\n",
    "    preds = reg.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, reg.predict(X_train))\n",
    "    mse_test = mean_squared_error(y_test,preds)\n",
    "\n",
    "    meta['mse_train'] = mse_train\n",
    "    meta['mse_test'] = mse_test\n",
    "    print('mse train ', str(meta['mse_train']))\n",
    "    print('mse test ', str(meta['mse_test']))\n",
    "    m = reg.coef_[0]\n",
    "    \n",
    "    c = reg.intercept_\n",
    "    line = lambda x: (x-c) /m\n",
    "\n",
    "    \n",
    "    #get the different band values and height for all x and y coordinates     \n",
    "    out = x.copy()\n",
    "    out['diff'] = y\n",
    "    out['x'] = reef['x']\n",
    "    out['y'] = reef['y']\n",
    "\n",
    "    meta['correlation'] = pearsonr(X_train.values, y_train.values)\n",
    "    return line, meta, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_log_outliers(data):\n",
    "    new_data = data.reset_index()\n",
    "    curr = -2\n",
    "    s = 0\n",
    "    while curr > min(data['Height']):\n",
    "        temp = new_data.loc[(new_data['Height'] < curr) & (new_data['Height'] > curr - 0.5)]\n",
    "\n",
    "        if len(temp) >= 1:\n",
    "            q1, q3= np.percentile(temp['diff'],[25,75])\n",
    "            iqr = q3-q1\n",
    "\n",
    "            outlier_range = 1.5 * iqr\n",
    "            lower_outlier = q1 - outlier_range\n",
    "            upper_outlier = q3 + outlier_range\n",
    "\n",
    "            drop_indices = temp.loc[(temp['diff'] < lower_outlier) | (temp['diff'] > upper_outlier)].index\n",
    "            s += len(drop_indices)\n",
    "\n",
    "            new_data = new_data.drop(drop_indices)\n",
    "\n",
    "        curr -= 1\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to predict the depth of the rest of the reef \n",
    "def predict_reef(reg, meta):\n",
    "    #creating lists to store required values \n",
    "    x = []\n",
    "    y = []\n",
    "    h = []\n",
    "\n",
    "    pix = []\n",
    "    log_pix = []\n",
    "    \n",
    "    #loads in the required images \n",
    "    b2_pix = meta['imgs'][0]\n",
    "    b3_pix = meta['imgs'][1]\n",
    "    b8_pix = meta['imgs'][3]\n",
    "    \n",
    "    #stores the masking threshold\n",
    "    mask_thresh = meta['mask_thresh']\n",
    "    \n",
    "    #looping through the image coordinates \n",
    "    for j in tqdm(range(len(b2_pix))):\n",
    "        for i in range(len(b2_pix[0])):\n",
    "            #getting the x and y coordinates \n",
    "            x_coord = meta['bbox'].Coordinates.x[0] + ((i)* meta['xdim']) + 5\n",
    "            y_coord = meta['bbox'].Coordinates.y[0] + ((j)* meta['ydim']) - 5\n",
    "            p = Point((x_coord, y_coord))\n",
    "            #checking if the point is within the reef\n",
    "            if meta['polygon'].loc[0,'geometry'].contains(p):\n",
    "                #getting the band values minus the dark pixel value \n",
    "#                 bp = meta['black_val']\n",
    "                bp = meta['min_pix']\n",
    "                band_2 = max(1,b2_pix[j][i] - bp['B02'])\n",
    "                band_3 = max(1,b3_pix[j][i] - bp['B03'])\n",
    "                band_8 = (b8_pix[j][i])\n",
    "                \n",
    "                #storing the pixel value \n",
    "                pix.append([b2_pix[j][i], b3_pix[j][i],b8_pix[j][i]])\n",
    "                #storing the normalised pixel value \n",
    "                log_pix.append([band_2,band_3,band_8])\n",
    "                #if the band 8 value is higher than the threshold we predict nan for the height \n",
    "                if band_8 > mask_thresh:\n",
    "                    h.append(np.nan)\n",
    "                    x.append(x_coord)\n",
    "                    y.append(y_coord)\n",
    "                    continue\n",
    "                #else we pass the band values into the regressor and adjust with the tide on the day \n",
    "                x.append(x_coord)\n",
    "                y.append(y_coord)\n",
    "                x_feat = math.log(band_2) -  math.log(band_3)\n",
    "                \n",
    "                pred = (reg(x_feat) - meta['tide_level'])\n",
    "#                 if pred >= 5: \n",
    "#                     h.append(np.nan)\n",
    "#                 else:\n",
    "                h.append(pred)\n",
    "    #creating a dataframe with the output information and save that df as a csv \n",
    "    df = pd.DataFrame([x,y,h,pix,log_pix]).T\n",
    "    df.columns = ['x','y','height','pixels','normalised_pixel']\n",
    "\n",
    "    out_fn = meta['reef_name']+'_out_'+ meta['dt'].strftime(\"%Y%m%d%H%M%S\") + '.csv'\n",
    "    out_fp = os.path.join(meta['outpath'], out_fn)\n",
    "    df.to_csv(out_fp)\n",
    "    return out_fp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_safe_files(data_dir,reef_name):\n",
    "    medians = []\n",
    "    variances = []\n",
    "    median_threshold = 1\n",
    "    variance_threshold = 0.5\n",
    "    datum = {}\n",
    "    reef_path = os.path.join(data_dir, reef_name)\n",
    "    \n",
    "    predictions_fp = os.path.join(reef_path,'Output', 'Depth Predictions')\n",
    "    if not os.path.exists(predictions_fp):\n",
    "        os.mkdir(predictions_fp)\n",
    "        \n",
    "    imgs_fp = os.path.join(predictions_fp, 'Imgs')\n",
    "    if not os.path.exists(imgs_fp):\n",
    "        os.mkdir(imgs_fp)\n",
    "        \n",
    "    csv_fp = os.path.join(predictions_fp, 'CSV_files')\n",
    "    if not os.path.exists(csv_fp):\n",
    "        os.mkdir(csv_fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    safe_files = os.path.join(reef_path, 'SAFE_files')\n",
    "    coords = depth.get_coords(reef_path)\n",
    "    for sf in os.listdir(safe_files):\n",
    "        if not sf.startswith('.'):\n",
    "            meta = {}\n",
    "            meta['outpath'] = csv_fp\n",
    "            meta['img_path'] = imgs_fp\n",
    "            meta['reef_name'] = reef_name\n",
    "            meta['coords'] = coords\n",
    "            meta['data_dir'] = data_dir\n",
    "            \n",
    "            pathlist = Path(safe_files).glob('**/' + sf + '/**/*.jp2')\n",
    "            img_path = os.path.dirname(list(pathlist)[0])\n",
    "            granule_path = os.path.dirname(img_path)\n",
    "            r,m,d = get_regressor(granule_path, meta)\n",
    "            sample_median = np.median(d['diff'])\n",
    "            sample_variance = np.var(d['diff'])\n",
    "\n",
    "            medians.append(sample_median)\n",
    "            variances.append(sample_variance)\n",
    "\n",
    "            if (sample_median < median_threshold and sample_median > -median_threshold) and \\\n",
    "            sample_variance < variance_threshold:\n",
    "                datum[sf] = (r,m,d)\n",
    "                preds = (predict_reef(r, m))\n",
    "                plot_reefs(preds,d,m,r)\n",
    "\n",
    "    plot_median_variance_graph(medians, variances, median_threshold, variance_threshold,meta['img_path'])\n",
    "    corr_plot(datum,reef_name,meta['img_path'])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to plot the reef depth histogram and a scatter plot of the same \n",
    "def plot_reefs(fp,data,meta,line):\n",
    "    df = pd.read_csv(fp)\n",
    "    #plot histogram of depths \n",
    "    fig, ax = plt.subplots(1,3,figsize = (28,12))\n",
    "    df['height'].plot.hist(bins = np.arange(-30,20,1), ax = ax[0])\n",
    "    ax[0].set_xlabel('Height (m)')\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "    ax[0].set_title(meta['reef_name'] + ' Depth Histogram')\n",
    "    \n",
    "    #getting just depths between +- 45m \n",
    "    df = df.loc[(df.height <= 10) & (df.height >= -25)]\n",
    "    #creating a color scale at 5m intervals \n",
    "\n",
    "    cmap = cm.colors.ListedColormap(['black','navy','mediumblue' ,'blue','royalblue', 'dodgerblue', \n",
    "                                     'skyblue','limegreen',  'lime' , 'yellow'\n",
    "                                      ,'orange','tomato',\n",
    "                                     'red','firebrick' ,'maroon'])\n",
    "    bounds = np.arange(-25,11,2.5)\n",
    "\n",
    "    norm = BoundaryNorm(bounds,cmap.N)\n",
    "    \n",
    "    # extract all colors from the .jet map\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "    # create the new map\n",
    "    cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "    # create a second axes for the colorbar\n",
    "    ax2 = fig.add_axes([0.9, 0.1, 0.03, 0.8])\n",
    "    cb = mpl.colorbar.ColorbarBase(ax2, cmap=cmap, norm=norm,\n",
    "        spacing='proportional', ticks=bounds, boundaries=bounds, format='%.1f')\n",
    "\n",
    "    \n",
    "    #scatter plot of the predicted depths \n",
    "    pts = ax[2].scatter(x = df.x, y = df.y, c = df.height, s= 1, cmap = cmap, norm = norm)\n",
    "    #scatter plot of the track lines from the ICESAT 2 data\n",
    "    ax[2].scatter(x = data.x, y= data.y, s = 3, c = 'black', label = 'ICESAT-2 tracks')\n",
    "    custom_lines = [Line2D([0], [0], color='black', lw=4)]\n",
    "    ax[2].legend(custom_lines, ['ICESAT-2 tracks'])\n",
    "    ax[2].set_xlabel('x')\n",
    "    ax[2].set_ylabel('y')\n",
    "    ax[2].set_title(meta['reef_name'] + ' Depth Predictions (m)')\n",
    "\n",
    "    \n",
    "    r = 3\n",
    "    sns.scatterplot(x = data['diff'], y = data.Height, color = 'blue', ax = ax[1])\n",
    "    sns.lineplot(x = [-r,r], y = [line(-r),line(r)], color = 'black', ax = ax[1])\n",
    "    ax[1].set_xlabel('Log(Blue Band) - Log(Green Band)')\n",
    "    ax[1].set_ylabel('Depth')\n",
    "    xt = (list(ax[1].get_xticks()))[:-1]\n",
    "    \n",
    "    for i,x in enumerate(xt):\n",
    "        xt[i] = np.round(x,2)\n",
    "    ax[1].set_title(str(meta['dt'].date()) + ' -> tide - ' + str(meta['tide_level']) + 'm')\n",
    "    xlim = (-r, r)\n",
    "    ylim = ( -25,0)\n",
    "    plt.setp(ax[1], xlim=xlim, ylim=ylim)\n",
    "    \n",
    "\n",
    "    fn = meta['reef_name'] + '-' + str(meta['dt'].date())+ '.png'\n",
    "    out = os.path.join(meta['img_path'], fn)\n",
    "    plt.savefig(out)\n",
    "    plt.close(fig)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_plot(datum,reef_name,outpath):\n",
    "    r = 6\n",
    "    num_blocks = int(np.ceil(np.sqrt(len(datum))))\n",
    "    fig, ax = plt.subplots(num_blocks,num_blocks, figsize = (20,24))\n",
    "    xlim = (-r, r)\n",
    "    ylim = ( -25,0)\n",
    "    plt.setp(ax, xlim=xlim, ylim=ylim)\n",
    "    \n",
    "    axlist = []\n",
    "    for axl in ax:\n",
    "        for axl2 in axl:\n",
    "            axlist.append(axl2)\n",
    "    \n",
    "    \n",
    "    day_keys = list(datum.keys())\n",
    "    for i,dict_item in enumerate(datum.items()):\n",
    "        d = dict_item[1][2]\n",
    "        line = dict_item[1][0]\n",
    "        meta = dict_item[1][1]\n",
    "        \n",
    "        sns.scatterplot(x = d['diff'], y = d.Height, color = 'blue', ax = axlist[i])\n",
    "        sns.lineplot(x = [-r,r], y = [line(-r),line(r)], color = 'black', ax = axlist[i])\n",
    "        axlist[i].set_xlabel('Log(Blue Band) - Log(Green Band)')\n",
    "        axlist[i].set_ylabel('Depth')\n",
    "        axlist[i].set_title(str(meta['dt'].date()))\n",
    "        xt = (list(axlist[i].get_xticks()))[:-1]\n",
    "        for i,x in enumerate(xt):\n",
    "            xt[i] = np.round(x,2)\n",
    "\n",
    "    fn = os.path.join(outpath,'corr_plot.png')\n",
    "    plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_median_variance_graph(medians, variances, median_threshold, variance_threshold,outpath):\n",
    "    ax=sns.scatterplot(x = medians, y = variances, legend = 'full')\n",
    "    plt.xlabel('Median pixel value for log difference')\n",
    "    plt.ylabel('Variance pixel value for log difference')\n",
    "\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            xy=(-median_threshold, -variance_threshold),  # point of origin.\n",
    "            width=2*median_threshold,\n",
    "            height=2*variance_threshold,\n",
    "            linewidth=1,\n",
    "            color='red',\n",
    "            fill=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fn = os.path.join(outpath,'median_vs_variance.png')\n",
    "    plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "all_safe_files('data','Moce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
